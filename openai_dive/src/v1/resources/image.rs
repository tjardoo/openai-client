#[cfg(feature = "download")]
use crate::v1::error::APIError;
#[cfg(feature = "download")]
use crate::v1::helpers::generate_file_name;
use crate::v1::resources::shared::FileUpload;
#[cfg(feature = "download")]
use base64::{engine::general_purpose, Engine as _};
use derive_builder::Builder;
#[cfg(feature = "download")]
use futures::future;
use serde::{Deserialize, Serialize};
use std::fmt::Display;

#[derive(Serialize, Deserialize, Debug, Default, Builder, Clone, PartialEq)]
#[builder(name = "CreateImageParametersBuilder")]
#[builder(setter(into, strip_option), default)]
pub struct CreateImageParameters {
    /// A text description of the desired image(s). The maximum length is 32000 characters for gpt-image-1, 1000 characters for dall-e-2 and 4000 characters for dall-e-3.
    pub prompt: String,
    /// Allows to set transparency for the background of the generated image(s). This parameter is only supported for gpt-image-1.
    /// Must be one of transparent, opaque or auto (default value). When auto is used, the model will automatically determine the best background for the image.
    /// If transparent, the output format needs to support transparency, so it should be set to either png (default value) or webp.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub background: Option<BackgroundStyle>,
    /// The model to use for image generation.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub model: Option<String>,
    /// Control the content-moderation level for images generated by gpt-image-1. Must be either low for less restrictive filtering or auto (default value).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub moderation: Option<ModerationLevel>,
    /// The number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub n: Option<u32>,
    /// The compression level (0-100%) for the generated images. This parameter is only supported for gpt-image-1 with the webp or jpeg output formats, and defaults to 100.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub output_compression: Option<u32>,
    /// The format in which the generated images are returned. This parameter is only supported for gpt-image-1. Must be one of png, jpeg, or webp.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub output_format: Option<OutputFormat>,
    /// The number of partial images to generate. This parameter is used for streaming responses that return partial images.
    /// Value must be between 0 and 3. When set to 0, the response will be a single image sent in one streaming event.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub partial_images: Option<u32>,
    /// The quality of the image that will be generated. hd creates images with finer details and greater consistency across the image.
    /// high, medium and low are supported for gpt-image-1. hd and standard are supported for dall-e-3. standard is the only option for dall-e-2.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub quality: Option<ImageQuality>,
    /// The format in which the generated images are returned. Must be one of url or b64_json.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub response_format: Option<ResponseFormat>,
    /// The size of the generated images. Must be one of 1024x1024, 1536x1024 (landscape), 1024x1536 (portrait), or auto (default value) for gpt-image-1,
    /// one of 256x256, 512x512, or 1024x1024 for dall-e-2, and one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub size: Option<ImageSize>,
    /// Generate the image in streaming mode.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub stream: Option<bool>,
    /// The style of the generated images. This parameter is only supported for dall-e-3. Must be one of vivid or natural.
    /// Vivid causes the model to lean towards generating hyper-real and dramatic images.
    /// Natural causes the model to produce more natural, less hyper-real looking images.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub style: Option<ImageStyle>,
    /// A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub safety_identifier: Option<String>,
    /// Used by OpenAI to cache responses for similar requests to optimize your cache hit rates.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub prompt_cache_key: Option<String>,
    /// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub user: Option<String>,
}

#[derive(Serialize, Deserialize, Debug, Default, Builder, Clone, PartialEq)]
#[builder(name = "EditImageParametersBuilder")]
#[builder(setter(into, strip_option), default)]
pub struct EditImageParameters {
    /// The image(s) to edit. Must be a supported image file or an array of images.
    /// If mask is not provided, image must have transparency, which will be used as the mask.
    pub image: FileUpload,
    /// A text description of the desired image(s). The maximum length is 1000 characters for dall-e-2, and 32000 characters for gpt-image-1.
    pub prompt: String,
    /// Allows to set transparency for the background of the generated image(s). This parameter is only supported for gpt-image-1.
    /// Must be one of transparent, opaque or auto (default value). When auto is used, the model will automatically determine the best background for the image.
    /// If transparent, the output format needs to support transparency, so it should be set to either png (default value) or webp.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub background: Option<BackgroundStyle>,
    /// Control how much effort the model will exert to match the style and features, especially facial features, of input images.
    /// This parameter is only supported for gpt-image-1. Unsupported for gpt-image-1-mini. Supports high and low. Defaults to low.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub input_fidelity: Option<InputFidelity>,
    /// An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where image should be edited.
    /// If there are multiple images provided, the mask will be applied on the first image.
    /// Must be a valid PNG file, less than 4MB, and have the same dimensions as image.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub mask: Option<FileUpload>,
    /// The mime type of the image. If not provided, the mime type will be set to application/octet-stream.
    /// gpt-image-1 expects `image/png`, `image/jpeg` or `image/webp`.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub mime_type: Option<MimeType>,
    /// The model to use for image generation.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub model: Option<String>,
    /// The number of images to generate. Must be between 1 and 10.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub n: Option<u32>,
    /// The compression level (0-100%) for the generated images. This parameter is only supported for gpt-image-1 with the webp or jpeg output formats, and defaults to 100.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub output_compression: Option<u32>,
    /// The format in which the generated images are returned. This parameter is only supported for gpt-image-1. Must be one of png, jpeg, or webp. The default value is png.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub output_format: Option<OutputFormat>,
    /// The number of partial images to generate. This parameter is used for streaming responses that return partial images.
    /// Value must be between 0 and 3. When set to 0, the response will be a single image sent in one streaming event.
    /// Note that the final image may be sent before the full number of partial images are generated if the full image is generated more quickly.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub partial_images: Option<u32>,
    /// The quality of the image that will be generated. hd creates images with finer details and greater consistency across the image.
    /// high, medium and low are supported for gpt-image-1. dall-e-2 only supports standard quality.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub quality: Option<ImageQuality>,
    /// The format in which the generated images are returned. Must be one of url or b64_json. URLs are only valid for 60 minutes after the image has been generated. This parameter is only supported for dall-e-2, as gpt-image-1 will always return base64-encoded images.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub response_format: Option<ResponseFormat>,
    /// The size of the generated images. Must be one of 1024x1024, 1536x1024 (landscape), 1024x1536 (portrait), or auto (default value) for gpt-image-1,
    /// one of 256x256, 512x512, or 1024x1024 for dall-e-2, and one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub size: Option<ImageSize>,
    /// Edit the image in streaming mode. Defaults to false. See the Image generation guide for more information.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub stream: Option<bool>,
    /// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub user: Option<String>,
}

#[derive(Serialize, Deserialize, Debug, Default, Builder, Clone, PartialEq)]
#[builder(name = "CreateImageVariationParametersBuilder")]
#[builder(setter(into, strip_option), default)]
pub struct CreateImageVariationParameters {
    /// The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.
    pub image: FileUpload,
    /// The model to use for image generation. Only dall-e-2 is supported at this time.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub model: Option<String>,
    /// The number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub n: Option<u32>,
    /// The format in which the generated images are returned. Must be one of url or b64_json.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub response_format: Option<ResponseFormat>,
    /// The size of the generated images. Must be one of 1024x1024, 1536x1024 (landscape), 1024x1536 (portrait), or auto (default value) for gpt-image-1,
    /// one of 256x256, 512x512, or 1024x1024 for dall-e-2, and one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub size: Option<ImageSize>,
    /// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub user: Option<String>,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub struct ImageResponse {
    /// The background parameter used for the image generation. Either transparent or opaque.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub background: Option<BackgroundStyle>,
    /// The Unix timestamp (in seconds) for when the image was created.
    pub created: u32,
    /// The list of generated images.
    pub data: Vec<ImageData>,
    /// The output format of the image generation. Either png, webp, or jpeg.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub output_format: Option<OutputFormat>,
    /// The quality of the image generated. Either low, medium, or high.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub quality: Option<ImageQuality>,
    /// The size of the image generated. Either 1024x1024, 1024x1536, or 1536x1024.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub size: Option<ImageSizeResponse>,
    /// For gpt-image-1 only, the token usage information for the image generation.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub usage: Option<ImageUsage>,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub enum ImageSize {
    #[serde(rename = "256x256")]
    Size256X256,
    #[serde(rename = "512x512")]
    Size512X512,
    #[serde(rename = "1024x1024")]
    Size1024X1024,
    #[serde(rename = "1024x1536")]
    Size1024X1536,
    #[serde(rename = "1536x1024")]
    Size1536X1024,
    #[serde(rename = "1792x1024")]
    Size1792X1024,
    #[serde(rename = "1024x1792")]
    Size1024X1792,
    #[serde(rename = "auto")]
    Auto,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub enum ImageSizeResponse {
    #[serde(rename = "256x256")]
    Size256X256,
    #[serde(rename = "512x512")]
    Size512X512,
    #[serde(rename = "1024x1024")]
    Size1024X1024,
    #[serde(rename = "1024x1536")]
    Size1024X1536,
    #[serde(rename = "1536x1024")]
    Size1536X1024,
    #[serde(rename = "1792x1024")]
    Size1792X1024,
    #[serde(rename = "1024x1792")]
    Size1024X1792,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum BackgroundStyle {
    Transparent,
    Opaque,
    Auto,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum ImageQuality {
    Standard,
    Hd,
    High,
    Medium,
    Low,
    Auto,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum MimeType {
    #[serde(rename = "image/png")]
    Png,
    #[serde(rename = "image/jpeg")]
    Jpeg,
    #[serde(rename = "image/webp")]
    Webp,
    #[serde(rename = "application/octet-stream")]
    OctetStream,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum ImageStyle {
    Vivid,
    Natural,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum ModerationLevel {
    Auto,
    Low,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum OutputFormat {
    Png,
    Jpeg,
    Webp,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum InputFidelity {
    High,
    Low,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum ResponseFormat {
    Url,
    B64Json,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub struct ImageUsage {
    /// The number of tokens (images and text) in the input prompt.
    pub input_tokens: u32,
    /// The input tokens detailed information for the image generation.
    pub input_tokens_details: Option<InputTokensDetails>,
    /// The number of output tokens generated by the model.
    pub output_tokens: u32,
    /// The total number of tokens (images and text) used for the image generation.
    pub total_tokens: u32,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
pub struct InputTokensDetails {
    /// The number of image tokens in the input.
    pub image_tokens: u32,
    /// The number of text tokens in the input.
    pub text_tokens: u32,
}

#[derive(Serialize, Deserialize, Debug, Clone, PartialEq)]
#[serde(untagged)]
pub enum ImageData {
    Url {
        url: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        revised_prompt: Option<String>,
    },
    B64Json {
        b64_json: String,
        #[serde(skip_serializing_if = "Option::is_none")]
        revised_prompt: Option<String>,
    },
}

impl ImageResponse {
    #[cfg(feature = "download")]
    pub async fn save(&self, path: &str) -> Result<Vec<String>, APIError> {
        let mut files = vec![];
        let mut handles = vec![];

        for item in self.data.clone() {
            let path = path.to_owned();

            handles.push(tokio::spawn(async move { item.save_to_disk(&path).await }));
        }

        let results = future::join_all(handles).await;

        for result in results {
            match result {
                Ok(path) => match path {
                    Ok(item) => files.push(item),
                    Err(_error) => (),
                },
                Err(_error) => (),
            }
        }

        Ok(files)
    }
}

impl ImageData {
    #[cfg(feature = "download")]
    pub async fn save_to_disk(&self, path: &str) -> Result<String, APIError> {
        match self {
            ImageData::Url { url, .. } => self.download_image_from_url(url, path).await,
            ImageData::B64Json { b64_json, .. } => {
                self.download_b64_json_image(b64_json, path).await
            }
        }
    }

    #[cfg(feature = "download")]
    async fn download_image_from_url(&self, url: &str, path: &str) -> Result<String, APIError> {
        let response = reqwest::get(url)
            .await
            .map_err(|error| APIError::FileError(error.to_string()))?;

        let full_path = generate_file_name(path, 16, "png");

        tokio::fs::write(
            &full_path,
            response
                .bytes()
                .await
                .map_err(|error| APIError::FileError(error.to_string()))?,
        )
        .await
        .map_err(|error| APIError::FileError(error.to_string()))?;

        Ok(full_path)
    }

    #[cfg(feature = "download")]
    async fn download_b64_json_image(
        &self,
        b64_json: &str,
        path: &str,
    ) -> Result<String, APIError> {
        let full_path = generate_file_name(path, 16, "png");

        let bytes = general_purpose::STANDARD.decode(b64_json).unwrap();

        tokio::fs::write(&full_path, bytes)
            .await
            .map_err(|error| APIError::FileError(error.to_string()))?;

        Ok(full_path)
    }
}

impl Display for InputFidelity {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{}",
            match self {
                InputFidelity::High => "high",
                InputFidelity::Low => "low",
            }
        )
    }
}

impl Display for OutputFormat {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{}",
            match self {
                OutputFormat::Png => "png",
                OutputFormat::Jpeg => "jpeg",
                OutputFormat::Webp => "webp",
            }
        )
    }
}

impl Display for BackgroundStyle {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{}",
            match self {
                BackgroundStyle::Transparent => "transparent",
                BackgroundStyle::Opaque => "opaque",
                BackgroundStyle::Auto => "auto",
            }
        )
    }
}

impl Display for ImageQuality {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{}",
            match self {
                ImageQuality::Standard => "standard",
                ImageQuality::Hd => "hd",
                ImageQuality::High => "high",
                ImageQuality::Medium => "medium",
                ImageQuality::Low => "low",
                ImageQuality::Auto => "auto",
            }
        )
    }
}

impl Display for ImageSize {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{}",
            match self {
                ImageSize::Size256X256 => "256x256",
                ImageSize::Size512X512 => "512x512",
                ImageSize::Size1024X1024 => "1024x1024",
                ImageSize::Size1536X1024 => "1536x1024",
                ImageSize::Size1024X1536 => "1024x1536",
                ImageSize::Size1792X1024 => "1792x1024",
                ImageSize::Size1024X1792 => "1024x1792",
                ImageSize::Auto => "auto",
            }
        )
    }
}

impl Display for MimeType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{}",
            match self {
                MimeType::Png => "image/png",
                MimeType::Jpeg => "image/jpeg",
                MimeType::Webp => "image/webp",
                MimeType::OctetStream => "application/octet-stream",
            }
        )
    }
}

impl Display for ResponseFormat {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "{}",
            match self {
                ResponseFormat::Url => "url",
                ResponseFormat::B64Json => "b64_json",
            }
        )
    }
}
